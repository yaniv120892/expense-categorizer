import logging
import fasttext
import requests  # For downloading model from S3
import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from deep_translator import GoogleTranslator
from mangum import Mangum  # Required for Vercel deployment
from dotenv import load_dotenv  # Load environment variables from .env
import sys

# Load environment variables from .env (only in local environment)
load_dotenv()

# Configure logging
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(message)s",
    level=logging.INFO,
    handlers=[logging.StreamHandler()]
)

# Initialize FastAPI app 
app = FastAPI()

# ğŸ› ï¸ Replace with your actual S3 URLs
S3_BUCKET_URL = os.getenv("S3_BUCKET_URL")
if not S3_BUCKET_URL:
    raise ValueError("âŒ Missing S3_BUCKET_URL environment variable!")

MODEL_URL = f"{S3_BUCKET_URL}/expense_categorizer.ftz"

# Temporary storage paths (Vercel allows using `/tmp`)
MODEL_PATH = "/tmp/expense_categorizer.ftz"

# ğŸ”½ Function to download files from S3
def download_file(url, path):
    if not os.path.exists(path):  # Avoid re-downloading
        logging.info(f"ğŸ“¥ Downloading {url} to {path}...")
        response = requests.get(url)
        if response.status_code == 200:
            with open(path, "wb") as f:
                f.write(response.content)
            logging.info(f"âœ… Downloaded {path}")
        else:
            logging.error(f"âŒ Failed to download {url}")
            raise Exception(f"Failed to download {url}")

# ğŸ”½ Download models if they donâ€™t exist
download_file(MODEL_URL, MODEL_PATH)

# ğŸ”½ Load models
try:
    fasttext_model = fasttext.load_model(MODEL_PATH)  # Load FastText model
    logging.info("âœ… FastText model loaded successfully.")
except Exception as e:
    logging.error(f"âŒ Error loading model: {e}")
    raise

# Initialize Translator
translator = GoogleTranslator(source="auto", target="en")

class ExpenseRequest(BaseModel):
    description: str

@app.post("/predict")
def predict_category(expense: ExpenseRequest):
    logging.info(f"ğŸ” Received prediction request: {expense.description}")

    try:
        # ğŸ”¹ Translate to English if needed
        translated_text = translator.translate(expense.description)
        logging.info(f"ğŸŒ Translated description: {translated_text}")

        # ğŸ”¹ Predict category using FastText
        predicted_label = fasttext_model.predict(translated_text)[0][0]  # e.g., '__label__food'
        category = predicted_label.replace("__label__", "")  # Remove FastText label prefix

        logging.info(f"âœ… Predicted category: {category}")
        return {"category": category, "translated_description": translated_text}

    except Exception as e:
        logging.error(f"âŒ Error during prediction: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

# Health check endpoint
@app.get("/ping")
def health_check():
    logging.info("ğŸ“ Received ping request.")
    return {"status": "alive"}

logging.info(f"ğŸ Python version: {sys.version}")
logging.info(f"ğŸ“¦ Installed packages: {sys.modules.keys()}")

try:
    handler = Mangum(app, lifespan="off")
    logging.info("âœ… Mangum initialized successfully")
except Exception as e:
    logging.error(f"âŒ Mangum initialization failed: {e}")
    raise